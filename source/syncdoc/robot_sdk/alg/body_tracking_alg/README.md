# Body_tracking_alg 算法说明

## 配置功能说明：

通过 RGB 视频检测人脸框，将人脸框通知 ROS2 消息发布出去。

## 机器人实物：

| 设备名称             | 生产厂家 | 作用                                 | 参考链接                                |
| :------------------- | -------- | ------------------------------------ | --------------------------------------- |
| Orbbec Gemini2vl相机 | 奥比中光 | 3D结构光深度视觉相机，点云数据输入源 | https://item.jd.com/10085187988079.html |
|                      |          |                                      |                                         |

## 应用说明：

运行本应用示例，可以通过摄像头识别到人脸，将人脸框通过 ROS2 消息发布出去，使用的人脸框检测算法为 arcface 的算法，支持 100 个设备端使用。

### 功能包安装

1、安装gazebo

2、安装foxglove

或直接采用奥比附带提供的docker环境

### 编译

1、可以全编译 colcon build

2、单独编译本功能包 colcon build --packages-select body_tracking_alg

### 运行

ros2 launch bringup bringup_launch.py

### 仿真

通过foxglove可以查看摄像头识别人脸框的情况，通过gazebo可以模拟演示人脸移动控制小车运动情况。

可以 ros2 topic echo /robot_sdk/bbox_result 查看实时人脸框信息

## 接口说明：

### 话题、服务、动作

| 名称                     | 消息类型                    | 说明                           | 发起端      | 接收端             |
| ------------------------ | --------------------------- | ------------------------------ | ----------- | ------------------ |
| /robot_sdk/camera_result | sensor_msgs::msg::Image     | camera 节点发布的 RGB 视频数据 | camera 节点 | 本模块             |
| /robot_sdk/bbox_result   | geometry_msgs::msg::Polygon | 人脸框坐标数据                 | 本模块      | body_tracking 节点 |

    参数

conf/HumanDetectAlg_Cfg.txt 配置文件

| 名称(参数名) | 类型 | 说明 | 是否必须 | 支持的配置 | 默认值 | 是否支持运行时动态配置 |
| ------------ | ---- | ---- | -------- | ---------- | ------ | ---------------------- |
| 无           |      |      |          |            |        |                        |
|              |      |      |          |            |        |                        |

## 常见问题：

1、人脸识别跟随，使用gazebo仿真和真实机器人仿真存在差异，区别是真实机器人摄像头可以跟随着人脸转动对焦中心坐标

2、通过foxglove可以查看摄像头识别人脸框的情况，通过gazebo可以模拟演示人脸移动控制小车运动情况
